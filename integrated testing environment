import cv2
import base64
import tkinter as tk
from tkinter import filedialog
import numpy as np
import matplotlib.pyplot as plt
from googleapiclient.discovery import build
import os
import pickle
from google_auth_oauthlib.flow import InstalledAppFlow
from google.auth.transport.requests import Request
from datetime import datetime

# Your Vision API key
vision_api_key = 'AIzaSyDRB4CbKeF9ORqFpjHuPAHyY-S-O-UpVxc'

# Google Sheets API
SCOPES = ['https://www.googleapis.com/auth/spreadsheets']
SPREADSHEET_ID = '1qMGdUnf9elwG6JAVa8Zojcype6UpaUCdk64sDESnIk0'
RANGE_NAME = 'IN'

# Build the Vision API client
vision_service = build('vision', 'v1', developerKey=vision_api_key)

def capture_image():
    # Initialize the camera
    cap = cv2.VideoCapture(0)  # 0 represents the default camera

    # Check if the camera is opened successfully
    if not cap.isOpened():
        print("Error: Could not open the camera")
        return None

    # Capture a frame from the camera
    ret, frame = cap.read()

    # Release the camera
    cap.release()

    return frame

def send_to_vision_and_sheets(image):
    # Convert the image to PNG format and encode it in base64
    _, buffer = cv2.imencode('.png', image)
    encoded_image = base64.b64encode(buffer).decode('UTF-8')

    # Create the request body
    request_body = {
        'requests': [{
            'image': {
                'content': encoded_image
            },
            'features': [{
                'type': 'TEXT_DETECTION'
            }]
        }]
    }

    # Call the Vision API
    response = vision_service.images().annotate(body=request_body).execute()

    # Extract the text from the response
    extracted_text = response['responses'][0]['textAnnotations'][0]['description']
    print("Extracted text from the image:")
    print(extracted_text)

    # Draw bounding boxes around the detected text
    for text in response['responses'][0]['textAnnotations'][1:]:
        vertices = [(vertex['x'], vertex['y']) for vertex in text['boundingPoly']['vertices']]
        cv2.polylines(image, [np.array(vertices)], True, (0, 255, 0), 2)

    # Display the image with bounding boxes
    cv2.imshow('Captured Image', image)
    cv2.waitKey(2000)  # Display the image for 2 seconds
    cv2.destroyAllWindows()

    # Google Sheets API integration
    creds = None
    if os.path.exists('token.pickle'):
        with open('token.pickle', 'rb') as token:
            creds = pickle.load(token)
    if not creds or not creds.valid:
        if creds and creds.expired and creds.refresh_token:
            creds.refresh(Request())
        else:
            flow = InstalledAppFlow.from_client_secrets_file(
                'credentials.json', SCOPES)
            creds = flow.run_local_server(port=0)
        with open('token.pickle', 'wb') as token:
            pickle.dump(creds, token)

    sheets_service = build('sheets', 'v4', credentials=creds)
    sheet = sheets_service.spreadsheets()

    # Get the current timestamp
    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')

    # Send both the extracted text and the timestamp to Google Sheets
    values = [[extracted_text], [timestamp]]
    body = {'values': values}
    result = sheet.values().append(
        spreadsheetId=SPREADSHEET_ID,
        range=RANGE_NAME,
        valueInputOption='USER_ENTERED',
        body=body).execute()

def main_gui():
    # Create the main GUI window
    root = tk.Tk()
    root.title("OCR System")

    def on_start_click():
        # Capture an image using the camera
        captured_frame = capture_image()

        # Send the captured image to Vision API and then to Google Sheets
        send_to_vision_and_sheets(captured_frame)

    # Create the Start button
    start_button = tk.Button(root, text="Start OCR Process", command=on_start_click)
    start_button.pack(pady=20)

    # Run the Tkinter main loop
    root.mainloop()

# Start the main GUI
main_gui()
