import cv2
import base64
import tkinter as tk
from tkinter import messagebox, simpledialog
from googleapiclient.discovery import build
import os
import pickle
from google_auth_oauthlib.flow import InstalledAppFlow
from google.auth.transport.requests import Request
from datetime import datetime
import numpy as np
from PIL import Image, ImageTk
import time

# Your Vision API key
vision_api_key = 'AIzaSyDRB4CbKeF9ORqFpjHuPAHyY-S-O-UpVxc'

# Google Sheets API
SCOPES = ['https://www.googleapis.com/auth/spreadsheets']
SPREADSHEET_ID = '1qMGdUnf9elwG6JAVa8Zojcype6UpaUCdk64sDESnIk0'
RANGE_NAME = 'IN'

# Build the Vision API client
vision_service = build('vision', 'v1', developerKey=vision_api_key)

def increase_brightness(img, value=30):
    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
    h, s, v = cv2.split(hsv)

    lim = 255 - value
    v[v > lim] = 255
    v[v <= lim] += value

    final_hsv = cv2.merge((h, s, v))
    bright_img = cv2.cvtColor(final_hsv, cv2.COLOR_HSV2BGR)
    return bright_img

def preprocess_image(image):
    # Convert the image to grayscale
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    
    # Apply Gaussian blur with a different kernel size
    blurred = cv2.GaussianBlur(gray, (7, 7), 0)
    
    # Adjusting the CLAHE parameters
    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))
    enhanced_contrast = clahe.apply(blurred)
    
    # Tweaking the adaptive thresholding parameters
    binary_image = cv2.adaptiveThreshold(enhanced_contrast, 255, 
                                         cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
                                         cv2.THRESH_BINARY, 15, 4)
    
    return binary_image


def send_to_vision(image):
    _, buffer = cv2.imencode('.png', image)
    encoded_image = base64.b64encode(buffer).decode('UTF-8')
    request_body = {
        'requests': [{
            'image': {
                'content': encoded_image
            },
            'features': [{
                'type': 'TEXT_DETECTION'
            }]
        }]
    }

    response = vision_service.images().annotate(body=request_body).execute()
    if 'textAnnotations' not in response['responses'][0]:
        print("No text annotations found in the Vision API response.")
        return None

    raw_text = response['responses'][0]['textAnnotations'][0]['description']
    return raw_text

def send_to_google_sheets(data):
    # Authenticate and build the Google Sheets API client.
    creds = None
    if os.path.exists('token.pickle'):
        with open('token.pickle', 'rb') as token:
            creds = pickle.load(token)
    if not creds or not creds.valid:
        if creds and creds.expired and creds.refresh_token:
            creds.refresh(Request())
        else:
            flow = InstalledAppFlow.from_client_secrets_file(
                'credentials.json', SCOPES)
            creds = flow.run_local_server(port=0)
        with open('token.pickle', 'wb') as token:
            pickle.dump(creds, token)

    service = build('sheets', 'v4', credentials=creds)

    values = [[str(datetime.now()), data]]
    body = {
        'values': values
    }
    result = service.spreadsheets().values().append(
        spreadsheetId=SPREADSHEET_ID, range=RANGE_NAME,
        valueInputOption="RAW", body=body).execute()

def capture_image_from_camera():
    camera_index = 0
    cap = cv2.VideoCapture(camera_index)

    if not cap.isOpened():
        print(f"Error: Could not open the camera with index {camera_index}")
        return None

    time.sleep(1)  # Wait for 1 second
    ret, captured_frame = cap.read()

    cap.release()
    cv2.destroyAllWindows()

    return captured_frame

def main_gui():
    root = tk.Tk()
    root.title("OCR System")
    captured_frame = []

    def display_image(image):
        window = tk.Toplevel(root)
        height, width, _ = image.shape
        canvas = tk.Canvas(window, width=width, height=height)
        canvas.pack()
        photo = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        image_tk = ImageTk.PhotoImage(image=Image.fromarray(photo))
        canvas.create_image(width/2, height/2, image=image_tk)
        window.mainloop()

    def capture_and_display():
        frame = capture_image_from_camera()
        if frame is not None:
            captured_frame.clear()
            captured_frame.append(frame)
            preprocessed = preprocess_image(frame)
        
            combined = np.hstack((frame, cv2.cvtColor(preprocessed, cv2.COLOR_GRAY2BGR)))  # Display side by side
            display_image(combined)

    def on_proceed_click():
        if captured_frame:
            print("Processing captured frame for OCR...")
            preprocessed_frame = preprocess_image(captured_frame[0])
            extracted_text = send_to_vision(preprocessed_frame)
            if extracted_text:
                print(f"Extracted text: {extracted_text}")
                send_to_google_sheets(extracted_text)
                if "DOT" in extracted_text:
                    print("DOT found in the extracted text!")
            else:
                print("No text extracted.")
        else:
            print("No captured frame found.")

    capture_button = tk.Button(root, text="Capture Image", command=capture_and_display)
    capture_button.pack(pady=20)

    proceed_button = tk.Button(root, text="Proceed with OCR", command=on_proceed_click)
    proceed_button.pack(pady=20)

    retake_button = tk.Button(root, text="Retake Image", command=capture_and_display)
    retake_button.pack(pady=20)

    root.mainloop()

main_gui()
